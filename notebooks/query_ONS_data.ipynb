{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341eeeed",
   "metadata": {},
   "source": [
    "# Aquisição de dados no portal da ONS Dados Aberto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927206f",
   "metadata": {},
   "source": [
    "https://ons-aws-prod-opendata.s3.amazonaws.com/\n",
    "\n",
    "https://registry.opendata.aws/ons-opendata-portal/\n",
    "\n",
    "https://github.com/awslabs/open-data-registry/blob/main/datasets/ons-opendata-portal.yaml#L17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6d7b5",
   "metadata": {},
   "source": [
    "# Importanto bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc15782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import time\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5620bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de parâmetros\n",
    "plot = False\n",
    "data_limite = '2025-06-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fd33a",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7de5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher_horas_faltantes(df, metodo='spline', order=2):\n",
    "    \"\"\"\n",
    "    Preenche as horas faltantes no índice datetime do DataFrame, interpolando os valores de acordo com o método escolhido.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (pd.DataFrame): DataFrame com índice datetime e colunas numéricas.\n",
    "    metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "                  'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "                  'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "                  'akima', 'cubicspline', 'from_derivatives').\n",
    "                  Padrão: 'spline'.\n",
    "    order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com as horas corrigidas e valores interpolados.\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"O DataFrame está vazio. Nenhuma interpolação foi realizada.\")\n",
    "        return df\n",
    "\n",
    "    # Garante que o índice é datetime e remove valores inválidos\n",
    "    df = df.copy()\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "\n",
    "    if df.index.isna().any():\n",
    "        raise ValueError(\n",
    "            \"O índice contém valores não reconhecidos como datas.\")\n",
    "\n",
    "    # Criar um range de tempo contínuo com frequência de 1 hora\n",
    "    full_range = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq='h')\n",
    "\n",
    "    # Só reindexa se houver horas ausentes\n",
    "    if not df.index.equals(full_range):\n",
    "        df = df.reindex(full_range)\n",
    "\n",
    "    # Filtra apenas colunas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    if numeric_cols.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada para interpolação. Retornando DataFrame original.\")\n",
    "        return df\n",
    "\n",
    "    # Lista de métodos válidos\n",
    "    metodos_validos = [\n",
    "        'linear', 'time', 'index', 'values', 'pad', 'nearest', 'zero',\n",
    "        'slinear', 'quadratic', 'cubic', 'barycentric', 'polynomial', 'krogh',\n",
    "        'piecewise_polynomial', 'spline', 'pchip', 'akima', 'cubicspline', 'from_derivatives'\n",
    "    ]\n",
    "\n",
    "    # Aplicando o método de interpolação escolhido\n",
    "    try:\n",
    "        if metodo in metodos_validos:\n",
    "            if metodo in ['spline', 'polynomial'] and order is None:\n",
    "                order = 2  # Define um padrão se o usuário não passar\n",
    "            df[numeric_cols] = df[numeric_cols].interpolate(\n",
    "                method=metodo, order=order if metodo in ['spline', 'polynomial'] else None)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Método de interpolação inválido: '{metodo}'. Métodos disponíveis: {', '.join(metodos_validos)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao interpolar os dados: {e}\")\n",
    "        return df\n",
    "\n",
    "    # Aviso se existirem colunas não numéricas\n",
    "    if not non_numeric_cols.empty:\n",
    "        print(\n",
    "            f\"As colunas não numéricas foram ignoradas: {list(non_numeric_cols)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0119df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_carga_ons(  start: pd.Timestamp,\n",
    "                    end: pd.Timestamp,\n",
    "                    extension: str = 'csv',\n",
    "                    max_retries: int = 3,\n",
    "                    metodo='spline',\n",
    "                    order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Baixa arquivos públicos do ONS de um dataset específico em um intervalo de datas, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Parâmetros:\n",
    "    ----------\n",
    "    start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "    end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "    extension (str): Extensão do arquivo a ser baixado. \".csv\" ou \".xlsx\" ou \".parquet\".\n",
    "    max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "    metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "        'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "        'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "        'akima', 'cubicspline', 'from_derivatives').\n",
    "        Padrão: 'spline'.\n",
    "    order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Retorno:\n",
    "    -------\n",
    "    pd.DataFrame: DataFrame contendo os valores de carga com timestamps em UTC.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(end).tz is None else pd.Timestamp(end)\n",
    "       \n",
    "    # Inicializa 'Cargas' como um dataFrame vazio\n",
    "    cargas = pd.DataFrame()\n",
    "    \n",
    "    for year in range(start.year, end.year + 1):\n",
    "        attempts = 0\n",
    "        while attempts < max_retries:\n",
    "            try:\n",
    "                # Obtenção dos dados\n",
    "                url = f\"https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/curva-carga-ho/CURVA_CARGA_{year}.{extension}\"\n",
    "                response = requests.get(url)\n",
    "                data = pd.read_csv(StringIO(response.text), sep=';')\n",
    "                \n",
    "                # Pivotar os dados para o formato largo\n",
    "                data = data.pivot(index='din_instante', columns='nom_subsistema', values='val_cargaenergiahomwmed')\n",
    "                \n",
    "                # Converter o índice para datetime             \n",
    "                data.index = pd.to_datetime(data.index)\n",
    "                \n",
    "                # Preencher possíveis valores ausentes antes da interpolação\n",
    "                data.ffill(inplace=True)\n",
    "\n",
    "                # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "                data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "                # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "                data = data.reset_index(names=['Timestamp'])\n",
    "                                \n",
    "                # Aviso de que os dados foram baixados com sucesso\n",
    "                print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "                \n",
    "                # Adiciona o DataFrame ao DataFrame de cargas\n",
    "                cargas = pd.concat([cargas, data], ignore_index=True).drop_duplicates(subset='Timestamp', keep='last')\n",
    "\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempts += 1\n",
    "                print(\n",
    "                    f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "                if attempts < max_retries:\n",
    "                    print(\"Tentando novamente em 5 segundos...\")\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")     \n",
    "    \n",
    "    cargas['Timestamp'] = pd.to_datetime(cargas['Timestamp'])\n",
    "    cargas['Timestamp'] = cargas['Timestamp'].dt.tz_localize('Etc/GMT+3')           \n",
    "    return cargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ece55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_plotly(df, title=\"Gráfico Interativo com Plotly\"):\n",
    "    fig = go.Figure()\n",
    "    for col in df.columns:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[col], mode='lines', name=col))\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Tempo\",\n",
    "        yaxis_title=\"Valores\",\n",
    "        hovermode='x unified',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f953a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date_and_save(\n",
    "    file_path,\n",
    "    limit_date=None,\n",
    "    timezone='Europe/Paris'\n",
    "):\n",
    "    \"\"\"\n",
    "    Lê o CSV de preços day-ahead com coluna 'Timestamp' contendo timezone,\n",
    "    converte para o timezone desejado, filtra até a data limite (exclusivo)\n",
    "    e sobrescreve o arquivo original.\n",
    "\n",
    "    Parâmetros:\n",
    "    - file_path (str): Caminho para o arquivo CSV.\n",
    "    - limit_date (str): Data limite no formato 'YYYY-MM-DD' (exclusivo).\n",
    "    - timezone (str): Timezone desejado (ex: 'Europe/Paris').\n",
    "    \"\"\"\n",
    "    # Se a data limite não for fornecida a função não faz nada\n",
    "    if limit_date is None:\n",
    "        print(\"Nenhuma data limite fornecida. Nenhum filtro aplicado.\")\n",
    "        return\n",
    "\n",
    "    # Lê o CSV e converte 'Timestamp' para datetime com UTC\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'])\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True).dt.tz_convert(timezone)\n",
    "\n",
    "    # Aplica filtro até a data limite no timezone especificado\n",
    "    limit_date_tz = pd.Timestamp(limit_date, tz=timezone)\n",
    "    df = df[df['Timestamp'] < limit_date_tz]\n",
    "\n",
    "    # Sobrescreve o arquivo original\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd5b3c7",
   "metadata": {},
   "source": [
    "## Carga ONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0ad845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2000 adquiridos com sucesso.\n",
      "Dados de 2001 adquiridos com sucesso.\n",
      "Dados de 2002 adquiridos com sucesso.\n",
      "Dados de 2003 adquiridos com sucesso.\n",
      "Dados de 2004 adquiridos com sucesso.\n",
      "Dados de 2005 adquiridos com sucesso.\n",
      "Dados de 2006 adquiridos com sucesso.\n",
      "Dados de 2007 adquiridos com sucesso.\n",
      "Dados de 2008 adquiridos com sucesso.\n",
      "Dados de 2009 adquiridos com sucesso.\n",
      "Dados de 2010 adquiridos com sucesso.\n",
      "Dados de 2011 adquiridos com sucesso.\n",
      "Dados de 2012 adquiridos com sucesso.\n",
      "Dados de 2013 adquiridos com sucesso.\n",
      "Dados de 2014 adquiridos com sucesso.\n",
      "Dados de 2015 adquiridos com sucesso.\n",
      "Dados de 2016 adquiridos com sucesso.\n",
      "Dados de 2017 adquiridos com sucesso.\n",
      "Dados de 2018 adquiridos com sucesso.\n",
      "Dados de 2019 adquiridos com sucesso.\n",
      "Dados de 2020 adquiridos com sucesso.\n",
      "Dados de 2021 adquiridos com sucesso.\n",
      "Dados de 2022 adquiridos com sucesso.\n",
      "Dados de 2023 adquiridos com sucesso.\n",
      "Dados de 2024 adquiridos com sucesso.\n",
      "Dados de 2025 adquiridos com sucesso.\n",
      "Arquivo CSV salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/carga_ons.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "    if plot:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "        df.set_index('Timestamp', inplace=True)\n",
    "        plot_dataset_plotly(df)\n",
    "except FileNotFoundError:\n",
    "    # Aquisição das cargas da ONS de 2000 até o disponível em 2025\n",
    "    carga_ons = get_carga_ons(\n",
    "        start = pd.Timestamp('2000-01-01'),\n",
    "        end = pd.Timestamp('2025-12-31'),\n",
    "        extension='csv',\n",
    "        order=3\n",
    "    )\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if carga_ons is not None and not carga_ons.empty:\n",
    "        carga_ons.to_csv('./../data/carga_ons.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "        filter_by_date_and_save(\n",
    "            file_path='./../data/carga_ons.csv',\n",
    "            limit_date=data_limite,\n",
    "            timezone='America/Sao_Paulo')\n",
    "        if plot:\n",
    "            carga_ons['Timestamp'] = pd.to_datetime(carga_ons['Timestamp'])\n",
    "            carga_ons.set_index('Timestamp', inplace=True)\n",
    "            plot_dataset_plotly(carga_ons)\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
