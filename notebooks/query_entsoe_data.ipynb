{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisição de dados no portal da transparência da ENTSOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como conseguir a API Key para acessar os dados do portal da transparência da ENTSOE:\n",
    "\n",
    "https://uat-transparency.entsoe.eu/content/static_content/Static%20content/web%20api/how_to_get_security_token.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from api_key import API_KEY\n",
    "from datetime import datetime, timedelta\n",
    "from entsoe import EntsoePandasClient\n",
    "\n",
    "# Configuração do cliente Entsoe\n",
    "client = EntsoePandasClient(API_KEY)\n",
    "\n",
    "# Definição de parâmetros\n",
    "country_code = 'FR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher_horas_faltantes(df, metodo='spline', order=2):\n",
    "    \"\"\"\n",
    "    Preenche as horas faltantes no índice datetime do DataFrame, interpolando os valores de acordo com o método escolhido.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (pd.DataFrame): DataFrame com índice datetime e colunas numéricas.\n",
    "    metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "                  'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "                  'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "                  'akima', 'cubicspline', 'from_derivatives').\n",
    "                  Padrão: 'spline'.\n",
    "    order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com as horas corrigidas e valores interpolados.\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"O DataFrame está vazio. Nenhuma interpolação foi realizada.\")\n",
    "        return df\n",
    "\n",
    "    # Garante que o índice é datetime e remove valores inválidos\n",
    "    df = df.copy()\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "\n",
    "    if df.index.isna().any():\n",
    "        raise ValueError(\n",
    "            \"O índice contém valores não reconhecidos como datas.\")\n",
    "\n",
    "    # Criar um range de tempo contínuo com frequência de 1 hora\n",
    "    full_range = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq='h')\n",
    "\n",
    "    # Só reindexa se houver horas ausentes\n",
    "    if not df.index.equals(full_range):\n",
    "        df = df.reindex(full_range)\n",
    "\n",
    "    # Filtra apenas colunas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    if numeric_cols.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada para interpolação. Retornando DataFrame original.\")\n",
    "        return df\n",
    "\n",
    "    # Lista de métodos válidos\n",
    "    metodos_validos = [\n",
    "        'linear', 'time', 'index', 'values', 'pad', 'nearest', 'zero',\n",
    "        'slinear', 'quadratic', 'cubic', 'barycentric', 'polynomial', 'krogh',\n",
    "        'piecewise_polynomial', 'spline', 'pchip', 'akima', 'cubicspline', 'from_derivatives'\n",
    "    ]\n",
    "\n",
    "    # Aplicando o método de interpolação escolhido\n",
    "    try:\n",
    "        if metodo in metodos_validos:\n",
    "            if metodo in ['spline', 'polynomial'] and order is None:\n",
    "                order = 2  # Define um padrão se o usuário não passar\n",
    "            df[numeric_cols] = df[numeric_cols].interpolate(\n",
    "                method=metodo, order=order if metodo in ['spline', 'polynomial'] else None)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Método de interpolação inválido: '{metodo}'. Métodos disponíveis: {', '.join(metodos_validos)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao interpolar os dados: {e}\")\n",
    "        return df\n",
    "\n",
    "    # Aviso se existirem colunas não numéricas\n",
    "    if not non_numeric_cols.empty:\n",
    "        print(\n",
    "            f\"As colunas não numéricas foram ignoradas: {list(non_numeric_cols)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_ahead_prices(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém os preços day-ahead para um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            data = client.query_day_ahead_prices(\n",
    "                country_code, start=start, end=end)\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame(name='Day Ahead Price')\n",
    "\n",
    "            # Garantir que o índice está no formato datetime e converter para UTC\n",
    "            data.index = pd.to_datetime(data.index).tz_convert('UTC')\n",
    "\n",
    "            # Preencher possíveis valores ausentes antes da interpolação\n",
    "            data.ffill(inplace=True)\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém os a carga atual para um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            data = client.query_load(country_code, start=start, end=end)\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame()\n",
    "\n",
    "            # Garantir que o índice está no formato datetime e converter para UTC\n",
    "            data.index = pd.to_datetime(data.index).tz_convert('UTC')\n",
    "\n",
    "            # Preencher possíveis valores ausentes antes da interpolação\n",
    "            data.ffill(inplace=True)\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crossborder_flux(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém o fluxo de energia de um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            export_energy = client.query_physical_crossborder_allborders(\n",
    "                country_code, start=start, end=end, export=True, per_hour=True).drop(columns='sum')\n",
    "            import_energy = client.query_physical_crossborder_allborders(\n",
    "                country_code, start=start, end=end, export=False, per_hour=True).drop(columns='sum')\n",
    "\n",
    "            # Calcula o fluxo de energia\n",
    "            data = import_energy.subtract(export_energy, fill_value=0)\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame()\n",
    "\n",
    "            # Garantir que o índice está no formato datetime e converter para UTC\n",
    "            data.index = pd.to_datetime(data.index).tz_convert('UTC')\n",
    "\n",
    "            # Preencher possíveis valores ausentes antes da interpolação\n",
    "            data.ffill(inplace=True)\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generation(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, psr_type: str = None, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém os preços day-ahead para um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        psr_type (str, opcional): Tipo de geração a ser consultado. Se None, retorna todos os tipos disponíveis.\n",
    "            Os tipos de PSR que podem estar disponíveis são:\n",
    "                - 'B01' - Biomass\n",
    "                - 'B02' - Fossil Brown coal/Lignite\n",
    "                - 'B03' - Fossil Coal-derived gas\n",
    "                - 'B04' - Fossil Gas\n",
    "                - 'B05' - Fossil Hard coal\n",
    "                - 'B06' - Fossil Oil\n",
    "                - 'B07' - Fossil Oil shale\n",
    "                - 'B08' - Fossil Peat\n",
    "                - 'B09' - Geothermal\n",
    "                - 'B10' - Hydro Pumped Storage\n",
    "                - 'B11' - Hydro Run-of-river and poundage\n",
    "                - 'B12' - Hydro Water Reservoir\n",
    "                - 'B13' - Marine\n",
    "                - 'B14' - Nuclear\n",
    "                - 'B15' - Other renewable\n",
    "                - 'B16' - Solar\n",
    "                - 'B17' - Waste\n",
    "                - 'B18' - Wind Offshore\n",
    "                - 'B19' - Wind Onshore\n",
    "                - 'B20' - Other\n",
    "                - 'B21' - AC Link\n",
    "                - 'B22' - DC Link\n",
    "                - 'B23' - Substation\n",
    "                - 'B24' - Transformer\n",
    "                - 'B25' - Energy storage\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            data = client.query_generation(\n",
    "                country_code, start=start, end=end, psr_type=psr_type)\n",
    "\n",
    "            # Renomeando colunas de forma mais intuitiva apenas se houver MultiIndex\n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                data.columns = [\n",
    "                    f\"{source} {metric.replace('Actual ', '')}\" for source, metric in data.columns]\n",
    "\n",
    "            # Tornar negativas as colunas 'Consumption'\n",
    "            mask = pd.Index(data.columns).str.contains(\"Consumption\", na=False)\n",
    "            data.loc[:, mask] *= -1\n",
    "\n",
    "            # Somá-las com 'Aggregated'\n",
    "            data = (\n",
    "                data.T.groupby(\n",
    "                    lambda x: x.replace(\" Aggregated\", \"\").replace(\n",
    "                        \" Consumption\", \"\")\n",
    "                )\n",
    "                .sum()\n",
    "                .T\n",
    "            )\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame()\n",
    "\n",
    "            # Garantir que o índice está no formato datetime e converter para UTC\n",
    "            data.index = pd.to_datetime(data.index).tz_convert('UTC')\n",
    "\n",
    "            # Preencher possíveis valores ausentes antes da interpolação\n",
    "            data.ffill(inplace=True)\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Day Ahead Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV encontrado.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/day_ahead_prices.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    day_ahead_prices = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2025):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            prices = get_day_ahead_prices(\n",
    "                client, country_code=country_code, start=start, end=end)\n",
    "            day_ahead_prices[year] = prices\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if day_ahead_prices:\n",
    "        dahp = pd.concat(day_ahead_prices.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        dahp.to_csv('./../data/day_ahead_prices.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV encontrado.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/load.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    load = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2025):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            actual_load = get_load(\n",
    "                client, country_code=country_code, start=start, end=end, order=3)\n",
    "            load[year] = actual_load\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if load:\n",
    "        all_load = pd.concat(load.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        all_load.to_csv('./../data/load.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Actual Generation per Production Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV encontrado.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/gen.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    gen = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2025):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            actual_gen = get_generation(\n",
    "                client, country_code=country_code, start=start, end=end, order=3)\n",
    "            gen[year] = actual_gen\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if gen:\n",
    "        all_gen = pd.concat(gen.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        all_gen.to_csv('./../data/gen.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Crossborder Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV encontrado.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/flux.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    flux = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2025):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            actual_flux = get_crossborder_flux(\n",
    "                client, country_code=country_code, start=start, end=end, order=3)\n",
    "            flux[year] = actual_flux\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if flux:\n",
    "        all_flux = pd.concat(flux.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        all_flux.to_csv('./../data/flux.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
