{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisição de dados no portal da transparência da ENTSOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como conseguir a API Key para acessar os dados do portal da transparência da ENTSOE:\n",
    "\n",
    "https://uat-transparency.entsoe.eu/content/static_content/Static%20content/web%20api/how_to_get_security_token.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"ENTSOE_API_KEY\", \"\")\n",
    "\n",
    "# Configuração do cliente Entsoe\n",
    "client = EntsoePandasClient(API_KEY)\n",
    "\n",
    "# Definição de parâmetros\n",
    "country_code = 'FR'\n",
    "plot = False\n",
    "data_limite = '2025-06-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher_horas_faltantes(df, metodo='spline', order=2):\n",
    "    \"\"\"\n",
    "    Preenche as horas faltantes no índice datetime do DataFrame, interpolando os valores de acordo com o método escolhido.\n",
    "    Converte o índice para UTC para remover o efeito de horário de verão, e depois retorna ao timezone original.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (pd.DataFrame): DataFrame com índice datetime e colunas numéricas.\n",
    "    metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "                  'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "                  'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "                  'akima', 'cubicspline', 'from_derivatives').\n",
    "    order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com as horas corrigidas e valores interpolados.\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"O DataFrame está vazio. Nenhuma interpolação foi realizada.\")\n",
    "        return df\n",
    "\n",
    "    # Copia para não alterar o original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Garante que o índice é datetime e remove inválidos\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "\n",
    "    if df.index.isna().any():\n",
    "        raise ValueError(\"O índice contém valores não reconhecidos como datas.\")\n",
    "\n",
    "    # Armazena timezone original (se houver)\n",
    "    tz_original = df.index.tz\n",
    "\n",
    "    # Converte para UTC se for timezone-aware\n",
    "    if tz_original is not None:\n",
    "        df.index = df.index.tz_convert('UTC')\n",
    "    else:\n",
    "        df.index = df.index.tz_localize('UTC')  # uniformiza\n",
    "\n",
    "    # Cria range contínuo de tempo com frequência de 1 hora\n",
    "    full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h', tz='UTC')\n",
    "\n",
    "    # Só reindexa se houver horas ausentes\n",
    "    if not df.index.equals(full_range):\n",
    "        df = df.reindex(full_range)\n",
    "\n",
    "    # Colunas numéricas e não numéricas\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    if numeric_cols.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada para interpolação. Retornando DataFrame original.\")\n",
    "        return df\n",
    "\n",
    "    metodos_validos = [\n",
    "        'linear', 'time', 'index', 'values', 'pad', 'nearest', 'zero',\n",
    "        'slinear', 'quadratic', 'cubic', 'barycentric', 'polynomial', 'krogh',\n",
    "        'piecewise_polynomial', 'spline', 'pchip', 'akima', 'cubicspline', 'from_derivatives'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        if metodo in metodos_validos:\n",
    "            if metodo in ['spline', 'polynomial'] and order is None:\n",
    "                order = 2\n",
    "            df[numeric_cols] = df[numeric_cols].interpolate(\n",
    "                method=metodo,\n",
    "                order=order if metodo in ['spline', 'polynomial'] else None\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Método de interpolação inválido: '{metodo}'. Métodos disponíveis: {', '.join(metodos_validos)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao interpolar os dados: {e}\")\n",
    "        return df\n",
    "\n",
    "    if not non_numeric_cols.empty:\n",
    "        print(f\"As colunas não numéricas foram ignoradas: {list(non_numeric_cols)}\")\n",
    "\n",
    "    # Converte de volta para o timezone original\n",
    "    if tz_original is not None:\n",
    "        df.index = df.index.tz_convert(tz_original)\n",
    "    else:\n",
    "        df.index = df.index.tz_localize(None)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_ahead_prices(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém os preços day-ahead para um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            data = client.query_day_ahead_prices(\n",
    "                country_code, start=start, end=end)\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame(name='Day Ahead Price')\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém os a carga atual para um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            data = client.query_load(country_code, start=start, end=end)\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame()\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crossborder_flux(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém o fluxo de energia de um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            export_energy = client.query_physical_crossborder_allborders(\n",
    "                country_code, start=start, end=end, export=True, per_hour=True).drop(columns='sum')\n",
    "            import_energy = client.query_physical_crossborder_allborders(\n",
    "                country_code, start=start, end=end, export=False, per_hour=True).drop(columns='sum')\n",
    "\n",
    "            # Calcula o fluxo de energia\n",
    "            data = import_energy.subtract(export_energy, fill_value=0)\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame()\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generation(client, country_code: str, start: pd.Timestamp, end: pd.Timestamp, psr_type: str = None, max_retries: int = 3, metodo='spline', order=2) -> pd.DataFrame:  # type: ignore\n",
    "    \"\"\"\n",
    "    Obtém os preços day-ahead para um país específico em um período determinado, com tentativas automáticas em caso de falha.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente de API que fornece os preços.\n",
    "        country_code (str): Código do país.\n",
    "        start (pd.Timestamp): Data de início no formato Timestamp.\n",
    "        end (pd.Timestamp): Data de fim no formato Timestamp.\n",
    "        psr_type (str, opcional): Tipo de geração a ser consultado. Se None, retorna todos os tipos disponíveis.\n",
    "            Os tipos de PSR que podem estar disponíveis são:\n",
    "                - 'B01' - Biomass\n",
    "                - 'B02' - Fossil Brown coal/Lignite\n",
    "                - 'B03' - Fossil Coal-derived gas\n",
    "                - 'B04' - Fossil Gas\n",
    "                - 'B05' - Fossil Hard coal\n",
    "                - 'B06' - Fossil Oil\n",
    "                - 'B07' - Fossil Oil shale\n",
    "                - 'B08' - Fossil Peat\n",
    "                - 'B09' - Geothermal\n",
    "                - 'B10' - Hydro Pumped Storage\n",
    "                - 'B11' - Hydro Run-of-river and poundage\n",
    "                - 'B12' - Hydro Water Reservoir\n",
    "                - 'B13' - Marine\n",
    "                - 'B14' - Nuclear\n",
    "                - 'B15' - Other renewable\n",
    "                - 'B16' - Solar\n",
    "                - 'B17' - Waste\n",
    "                - 'B18' - Wind Offshore\n",
    "                - 'B19' - Wind Onshore\n",
    "                - 'B20' - Other\n",
    "                - 'B21' - AC Link\n",
    "                - 'B22' - DC Link\n",
    "                - 'B23' - Substation\n",
    "                - 'B24' - Transformer\n",
    "                - 'B25' - Energy storage\n",
    "        max_retries (int): Número máximo de tentativas antes de desistir.\n",
    "        metodo (str): Método de interpolação ('linear', 'time', 'index', 'values', 'pad', \n",
    "            'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'barycentric', \n",
    "            'polynomial', 'krogh', 'piecewise_polynomial', 'spline', 'pchip', \n",
    "            'akima', 'cubicspline', 'from_derivatives').\n",
    "            Padrão: 'spline'.\n",
    "        order (int, opcional): Ordem do polinômio para os métodos 'polynomial' e 'spline'. Padrão: 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os preços day-ahead com timestamps em UTC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Garante que os argumentos start e end são timestamps corretamente formatados\n",
    "    start = pd.Timestamp(start).tz_localize('UTC') if pd.Timestamp(\n",
    "        start).tz is None else pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end).tz_localize('UTC') if pd.Timestamp(\n",
    "        end).tz is None else pd.Timestamp(end)\n",
    "\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Obtenção dos dados\n",
    "            data = client.query_generation(\n",
    "                country_code, start=start, end=end, psr_type=psr_type)\n",
    "\n",
    "            # Renomeando colunas de forma mais intuitiva apenas se houver MultiIndex\n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                data.columns = [\n",
    "                    f\"{source} {metric.replace('Actual ', '')}\" for source, metric in data.columns]\n",
    "\n",
    "            # Tornar negativas as colunas 'Consumption'\n",
    "            mask = pd.Index(data.columns).str.contains(\"Consumption\", na=False)\n",
    "            data.loc[:, mask] *= -1\n",
    "\n",
    "            # Somá-las com 'Aggregated'\n",
    "            data = (\n",
    "                data.T.groupby(\n",
    "                    lambda x: x.replace(\" Aggregated\", \"\").replace(\n",
    "                        \" Consumption\", \"\")\n",
    "                )\n",
    "                .sum()\n",
    "                .T\n",
    "            )\n",
    "\n",
    "            # Se for uma Series, converte para DataFrame com nome de coluna adequado\n",
    "            if isinstance(data, pd.Series):\n",
    "                data = data.to_frame()\n",
    "\n",
    "            # Preenchimento de horas faltantes usando spline de ordem 2\n",
    "            data = preencher_horas_faltantes(data, metodo=metodo, order=order)\n",
    "\n",
    "            # Resetar o índice e nomear corretamente a coluna de timestamp\n",
    "            data = data.reset_index(names=['Timestamp'])\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Erro ao obter os dados de {start.year} (Tentativa {attempts}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempts < max_retries:\n",
    "                print(\"Tentando novamente em 5 segundos...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Falha após {max_retries} tentativas. Pulando ano {start.year}.\")\n",
    "                # Retorna um DataFrame vazio para evitar falhas no código principal.\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_plotly(df, title=\"Gráfico Interativo com Plotly\"):\n",
    "    fig = go.Figure()\n",
    "    for col in df.columns:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[col], mode='lines', name=col))\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Tempo\",\n",
    "        yaxis_title=\"Valores\",\n",
    "        hovermode='x unified',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date_and_save(\n",
    "    file_path,\n",
    "    limit_date=None,\n",
    "    timezone='Europe/Paris'\n",
    "):\n",
    "    \"\"\"\n",
    "    Lê o CSV de preços day-ahead com coluna 'Timestamp' contendo timezone,\n",
    "    converte para o timezone desejado, filtra até a data limite (exclusivo)\n",
    "    e sobrescreve o arquivo original.\n",
    "\n",
    "    Parâmetros:\n",
    "    - file_path (str): Caminho para o arquivo CSV.\n",
    "    - limit_date (str): Data limite no formato 'YYYY-MM-DD' (exclusivo).\n",
    "    - timezone (str): Timezone desejado (ex: 'Europe/Paris').\n",
    "    \"\"\"\n",
    "    # Se a data limite não for fornecida a função não faz nada\n",
    "    if limit_date is None:\n",
    "        print(\"Nenhuma data limite fornecida. Nenhum filtro aplicado.\")\n",
    "        return\n",
    "\n",
    "    # Lê o CSV e converte 'Timestamp' para datetime com UTC\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'])\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True).dt.tz_convert(timezone)\n",
    "\n",
    "    # Aplica filtro até a data limite no timezone especificado\n",
    "    limit_date_tz = pd.Timestamp(limit_date, tz=timezone)\n",
    "    df = df[df['Timestamp'] < limit_date_tz]\n",
    "\n",
    "    # Sobrescreve o arquivo original\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Day Ahead Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2015 adquiridos com sucesso.\n",
      "Dados de 2016 adquiridos com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 10 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2017 adquiridos com sucesso.\n",
      "Dados de 2018 adquiridos com sucesso.\n",
      "Dados de 2019 adquiridos com sucesso.\n",
      "Dados de 2020 adquiridos com sucesso.\n",
      "Dados de 2021 adquiridos com sucesso.\n",
      "Dados de 2022 adquiridos com sucesso.\n",
      "Dados de 2023 adquiridos com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 10 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2024 adquiridos com sucesso.\n",
      "Dados de 2025 adquiridos com sucesso.\n",
      "Arquivo CSV salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/day_ahead_prices.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "    if plot:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "        df.set_index('Timestamp', inplace=True)\n",
    "        plot_dataset_plotly(df)\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    day_ahead_prices = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2026):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            prices = get_day_ahead_prices(\n",
    "                client, country_code=country_code, start=start, end=end)\n",
    "            day_ahead_prices[year] = prices\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if day_ahead_prices:\n",
    "        dahp = pd.concat(day_ahead_prices.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        dahp.to_csv('./../data/day_ahead_prices.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "        filter_by_date_and_save(\n",
    "            file_path='./../data/day_ahead_prices.csv',\n",
    "            limit_date=data_limite,\n",
    "            timezone='Europe/Paris')\n",
    "        if plot:\n",
    "            dahp['Timestamp'] = pd.to_datetime(dahp['Timestamp'], utc=True)\n",
    "            dahp.set_index('Timestamp', inplace=True)\n",
    "            plot_dataset_plotly(dahp)\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2015 adquiridos com sucesso.\n",
      "Dados de 2016 adquiridos com sucesso.\n",
      "Dados de 2017 adquiridos com sucesso.\n",
      "Dados de 2018 adquiridos com sucesso.\n",
      "Dados de 2019 adquiridos com sucesso.\n",
      "Dados de 2020 adquiridos com sucesso.\n",
      "Dados de 2021 adquiridos com sucesso.\n",
      "Dados de 2022 adquiridos com sucesso.\n",
      "Dados de 2023 adquiridos com sucesso.\n",
      "Dados de 2024 adquiridos com sucesso.\n",
      "Dados de 2025 adquiridos com sucesso.\n",
      "Arquivo CSV salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/load.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "    if plot:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "        df.set_index('Timestamp', inplace=True)\n",
    "        plot_dataset_plotly(df)\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    load = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2026):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            actual_load = get_load(\n",
    "                client, country_code=country_code, start=start, end=end, order=3)\n",
    "            load[year] = actual_load\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if load:\n",
    "        all_load = pd.concat(load.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        all_load.to_csv('./../data/load.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "        filter_by_date_and_save(\n",
    "            file_path='./../data/load.csv',\n",
    "            limit_date=data_limite,\n",
    "            timezone='Europe/Paris')\n",
    "        if plot:\n",
    "            all_load['Timestamp'] = pd.to_datetime(all_load['Timestamp'], utc=True)\n",
    "            all_load.set_index('Timestamp', inplace=True)\n",
    "            plot_dataset_plotly(all_load)\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Actual Generation per Production Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2015 adquiridos com sucesso.\n",
      "Dados de 2016 adquiridos com sucesso.\n",
      "Dados de 2017 adquiridos com sucesso.\n",
      "Dados de 2018 adquiridos com sucesso.\n",
      "Dados de 2019 adquiridos com sucesso.\n",
      "Dados de 2020 adquiridos com sucesso.\n",
      "Dados de 2021 adquiridos com sucesso.\n",
      "Dados de 2022 adquiridos com sucesso.\n",
      "Dados de 2023 adquiridos com sucesso.\n",
      "Dados de 2024 adquiridos com sucesso.\n",
      "Dados de 2025 adquiridos com sucesso.\n",
      "Arquivo CSV salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/gen.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "    if plot:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "        df.set_index('Timestamp', inplace=True)\n",
    "        plot_dataset_plotly(df)\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    gen = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2026):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            actual_gen = get_generation(\n",
    "                client, country_code=country_code, start=start, end=end, order=3)\n",
    "            gen[year] = actual_gen\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if gen:\n",
    "        all_gen = pd.concat(gen.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        all_gen.to_csv('./../data/gen.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "        filter_by_date_and_save(\n",
    "            file_path='./../data/gen.csv',\n",
    "            limit_date=data_limite,\n",
    "            timezone='Europe/Paris')\n",
    "        if plot:\n",
    "            all_gen['Timestamp'] = pd.to_datetime(all_gen['Timestamp'], utc=True)\n",
    "            all_gen.set_index('Timestamp', inplace=True)\n",
    "            plot_dataset_plotly(all_gen)\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Crossborder Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2015 adquiridos com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 10 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de 2016 adquiridos com sucesso.\n",
      "Dados de 2017 adquiridos com sucesso.\n",
      "Dados de 2018 adquiridos com sucesso.\n",
      "Dados de 2019 adquiridos com sucesso.\n",
      "Dados de 2020 adquiridos com sucesso.\n",
      "Dados de 2021 adquiridos com sucesso.\n",
      "Dados de 2022 adquiridos com sucesso.\n",
      "Dados de 2023 adquiridos com sucesso.\n",
      "Dados de 2024 adquiridos com sucesso.\n",
      "Dados de 2025 adquiridos com sucesso.\n",
      "Arquivo CSV salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o csv já existe\n",
    "try:\n",
    "    df = pd.read_csv('./../data/flux.csv')\n",
    "    print(\"Arquivo CSV encontrado.\")\n",
    "    if plot:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "        df.set_index('Timestamp', inplace=True)\n",
    "        plot_dataset_plotly(df)\n",
    "except FileNotFoundError:\n",
    "    # Inicializa um dicionário para armazenar os preços por ano\n",
    "    flux = {}\n",
    "\n",
    "    # Aquisição dos preços day-ahead para a França de 2015 até o primeiro dado de 2025\n",
    "    for year in range(2015, 2026):\n",
    "\n",
    "        start = pd.Timestamp(f'{year}0101', tz='UTC')\n",
    "        end = pd.Timestamp(f'{year + 1}0101', tz='UTC')\n",
    "\n",
    "        try:\n",
    "            actual_flux = get_crossborder_flux(\n",
    "                client, country_code=country_code, start=start, end=end, order=3)\n",
    "            flux[year] = actual_flux\n",
    "            print(f\"Dados de {year} adquiridos com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter os dados de {year}: {e}\")\n",
    "\n",
    "    # Concatenar todos os DataFrames, tratando duplicatas pela coluna Timestamp\n",
    "    if flux:\n",
    "        all_flux = pd.concat(flux.values(), ignore_index=True).drop_duplicates(\n",
    "            subset='Timestamp', keep='last')\n",
    "\n",
    "        # Armazenar os dados em um arquivo CSV\n",
    "        all_flux.to_csv('./../data/flux.csv', index=False)\n",
    "        print(\"Arquivo CSV salvo com sucesso.\")\n",
    "        filter_by_date_and_save(\n",
    "            file_path='./../data/flux.csv',\n",
    "            limit_date=data_limite,\n",
    "            timezone='Europe/Paris')\n",
    "        if plot:\n",
    "            all_flux['Timestamp'] = pd.to_datetime(all_flux['Timestamp'], utc=True)\n",
    "            all_flux.set_index('Timestamp', inplace=True)\n",
    "            plot_dataset_plotly(all_flux)\n",
    "    else:\n",
    "        print(\"Nenhum dado foi adquirido, arquivo CSV não gerado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
