{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disponibilidade de GPU: True\n",
      "Número de GPUs disponíveis: 1\n",
      "ID da GPU atualmente em uso: 0\n"
     ]
    }
   ],
   "source": [
    "# Verifica se a GPU está disponível\n",
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "if gpu_available:\n",
    "    # Obtém o número de GPUs disponíveis\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    # Obtém o ID da GPU atualmente em uso\n",
    "    current_gpu = torch.cuda.current_device()\n",
    "\n",
    "    print(f\"Disponibilidade de GPU: {gpu_available}\")\n",
    "    print(f\"Número de GPUs disponíveis: {num_gpus}\")\n",
    "    print(f\"ID da GPU atualmente em uso: {current_gpu}\")\n",
    "else:\n",
    "    print(\"GPU não está disponível. Utilizando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Github\\TCC\\pytorch.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, seq \u001b[39min\u001b[39;00m loop:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     model\u001b[39m.\u001b[39mhidden_cell \u001b[39m=\u001b[39m (\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m         torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, model\u001b[39m.\u001b[39;49mhidden_layer_size)\u001b[39m.\u001b[39;49mto(device),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m         torch\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, model\u001b[39m.\u001b[39mhidden_layer_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     seq \u001b[39m=\u001b[39m seq[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Github/TCC/pytorch.ipynb#W1sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model(seq)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Carregar dados\n",
    "data = pd.read_csv('../TCC/datasets/forecast_dap.csv')\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp']).dt.strftime('%Y-%m-%d %H:%M')\n",
    "data.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Escolher a coluna alvo\n",
    "target_column = 'Day Ahead Price'\n",
    "data = data[[target_column]]\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Definir janela de tempo e criar sequências\n",
    "window_size = 24  # Escolher o tamanho da janela para previsão\n",
    "train_data = data_normalized[:-window_size]  # Dados de treino\n",
    "test_data = data_normalized[-window_size:]  # Últimos 24 pontos para teste\n",
    "\n",
    "# Converter para tensores\n",
    "def create_sequences(data, window_size):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        sequence = data[i:i+window_size]\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "train_sequences = create_sequences(train_data, window_size)\n",
    "test_sequences = create_sequences(test_data, window_size)\n",
    "\n",
    "# Converter para tensores do PyTorch\n",
    "train_sequences_tensor = torch.from_numpy(train_sequences).float()\n",
    "test_sequences_tensor = torch.from_numpy(test_sequences).float()\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_sequences_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4096, shuffle=True)\n",
    "\n",
    "# Definir modelo LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "# Inicializar o modelo\n",
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Verifique se a GPU está disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Mova o modelo e os tensores para a GPU, se disponível\n",
    "model.to(device)\n",
    "train_sequences_tensor = train_sequences_tensor.to(device)\n",
    "test_sequences_tensor = test_sequences_tensor.to(device)\n",
    "\n",
    "# Treinar o modelo\n",
    "epochs = 100\n",
    "print_every = 10  # Imprimir a perda a cada 10 iterações\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Usar tqdm para criar a barra de progresso\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    for i, seq in loop:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (\n",
    "            torch.zeros(1, 1, model.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, model.hidden_layer_size).to(device)\n",
    "        )\n",
    "\n",
    "        seq = seq[0].view(-1, 1, 1).to(device)\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        y_pred = y_pred.view(-1)\n",
    "\n",
    "        loss = criterion(y_pred, seq[-1].view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            loop.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            loop.set_postfix(loss=loss.item())  # Atualizar a perda na barra de progresso\n",
    "\n",
    "# Fazer previsões\n",
    "future = 24\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_seq = test_sequences_tensor[:1].to(device)\n",
    "    preds = []\n",
    "    for _ in range(future):\n",
    "        test_seq = test_seq.view(-1, 1, 1)\n",
    "\n",
    "        y_test_pred = model(test_seq)\n",
    "        preds.append(y_test_pred.item())\n",
    "\n",
    "        new_seq = test_seq.cpu().numpy().flatten()\n",
    "        new_seq = np.append(new_seq, y_test_pred.cpu())\n",
    "        new_seq = new_seq[1:]\n",
    "        test_seq = torch.as_tensor(new_seq).view(1, -1, 1).float().to(device)\n",
    "\n",
    "# Inverter a normalização\n",
    "predicted_values = scaler.inverse_transform(np.array(preds).reshape(-1, 1))\n",
    "print(\"Previsões para os próximos 24 pontos:\", predicted_values.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
